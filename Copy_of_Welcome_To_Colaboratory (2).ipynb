{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from PIL import Image, ImageOps\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "#parser = argparse.ArgumentParser()\n",
        "#parser.add_argument(\"filename\", type=str, help=\"filename of the image to process\")\n",
        "#opt = parser.parse_args()\n",
        "# Load the model\n",
        "model = load_model('keras_model[1].h5')\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "# Replace this with the path to your image\n",
        "image = Image.open('images (28).jpg')\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "print(\"Confidence level in all classes: \" + str(prediction))\n",
        "greatest_guess = 0\n",
        "index = 0\n",
        "count = 0\n",
        "for predictions in prediction:\n",
        "  for guess in predictions:\n",
        "    if guess > greatest_guess:\n",
        "      greatest_guess = guess\n",
        "      index = count\n",
        "    count+= 1\n",
        "\n",
        "classes = [\"cat\", \"dog\"]\n",
        "print(\"Class with greatest confidence was: \" + str(classes[index]))\n",
        "print(\"With a confidence of: \" + str(greatest_guess))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_3T89p_NiPb",
        "outputId": "b37a2d53-08b0-4056-bcd4-0293d342412a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Confidence level in all classes: [[5.7335926e-04 9.9906713e-01 3.5951205e-04]]\n",
            "Class with greatest confidence was: dog\n",
            "With a confidence of: 0.9990671\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy_of_Welcome_To_Colaboratory.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}